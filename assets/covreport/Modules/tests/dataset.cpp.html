<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml">
	<head>
        <meta charset="utf-8"/>
	    <title>dataset.cpp</title>
	    <link href="../../third-party/google-code-prettify/prettify-CppCoverage.css" type="text/css" rel="stylesheet" />
	    <script type="text/javascript" src="../../third-party/google-code-prettify/prettify.js"></script>
	</head>
    <body onload="prettyPrint()">
        <h4></h4>
        <pre class="prettyprint lang-cpp linenums">
#include &lt;thread&gt;

#include "argon2d.hpp"
#include "assertume.hpp"
#include "dataset.hpp"
#include "superscalar.hpp"

namespace modernRX {
    namespace {
        constexpr uint32_t Cache_Item_Count{ argon2d::Memory_Size / sizeof(DatasetItem) }; // Number of dataset items contained in cache.
        static_assert(std::has_single_bit(Cache_Item_Count)); // Vectorized code assumes that Cache_Item_Count is a power of 2.

        constexpr uint32_t Cache_Item_Mask{ Cache_Item_Count - 1 }; // Mask used to get cache item for dataset item calculation.
    }

<span style = "background-color:#dfd">    HeapArray&lt;DatasetItem, 4096&gt; generateDataset(const_span&lt;argon2d::Block&gt; cache, const_span&lt;SuperscalarProgram, Rx_Cache_Accesses&gt; programs) {</span>
        // Compile superscalar programs into single function.
<span style = "background-color:#dfd">        const auto jit{ compile(programs) };</span>

        // Dataset padding size adds additional memory to dataset to make it divisible by thread count * batch_size(4) without remainder.
        // This is needed to make sure that each thread will have the same amount of work and no additional function for handling remainders is needed.
        // Additional data will be ignored during hash calculation, its purpose is to simplify dataset generation.
<span style = "background-color:#dfd">        const uint32_t thread_count{ std::thread::hardware_concurrency() };
        const uint32_t dataset_alignment{ thread_count * 4 * sizeof(DatasetItem) };
        const uint32_t dataset_padding_size{ dataset_alignment - ((Rx_Dataset_Base_Size + Rx_Dataset_Extra_Size) % dataset_alignment) };
        const uint32_t dataset_items_count{ (Rx_Dataset_Base_Size + Rx_Dataset_Extra_Size + dataset_padding_size) / sizeof(DatasetItem) };
        const uint32_t items_per_thread{ dataset_items_count / thread_count };</span>

        // Allocate memory for dataset.
<span style = "background-color:#dfd">        HeapArray&lt;DatasetItem, 4096&gt; memory{ dataset_items_count };</span>

        // Split each thread task into smaller jobs. This is for reducing potential variances in execution.
<span style = "background-color:#dfd">        constexpr uint32_t Min_Items_Per_Job{ 32'768 }; // Value was chosen empirically.
        uint32_t task_divisor{ 1 };
        uint32_t new_dataset_padding_size = dataset_padding_size;
        while (items_per_thread / task_divisor &gt; Min_Items_Per_Job &amp;&amp; new_dataset_padding_size == dataset_padding_size) {
            task_divisor *= 2;
            const uint32_t new_dataset_alignment{ dataset_alignment * task_divisor };
            new_dataset_padding_size = new_dataset_alignment - ((Rx_Dataset_Base_Size + Rx_Dataset_Extra_Size) % new_dataset_alignment);
        }
        task_divisor = std::max&lt;uint32_t&gt;(1, task_divisor / 2); // Prevents task_divisor from being 0.</span>

<span style = "background-color:#dfd">        const uint32_t items_per_job{ items_per_thread / task_divisor };
        const uint32_t max_jobs{ dataset_items_count / items_per_job };
        std::atomic&lt;uint32_t&gt; job_counter{ 0 };</span>

        // Task that will be executed by each thread.
<span style = "background-color:#dfd">        const auto task = [max_jobs, items_per_job, &amp;job_counter, jit_program{ *jit }, cache_ptr{ cache.data() }](std::span&lt;DatasetItem&gt; memory) {
            auto job_id{ job_counter.fetch_add(1, std::memory_order_relaxed) };
            while (job_id &lt; max_jobs) {
                const auto start_item{ job_id * items_per_job };
                jit_program(memory.subspan(start_item, items_per_job), reinterpret_cast&lt;uintptr_t&gt;(cache_ptr), Cache_Item_Mask, start_item);
                job_id = job_counter.fetch_add(1, std::memory_order_relaxed);
            }
        };</span>

        // Start threads.
<span style = "background-color:#dfd">        std::vector&lt;std::thread&gt; threads{ thread_count };</span>

<span style = "background-color:#dfd">        for (uint32_t tid = 0; tid &lt; thread_count; ++tid) {
            threads[tid] = std::thread{ task, memory.buffer() };
        }</span>

        // Wait for threads to finish.
<span style = "background-color:#dfd">        for (uint64_t tid = 0; tid &lt; thread_count; ++tid) {
            threads[tid].join();
        }</span>

<span style = "background-color:#dfd">        return memory;
    }</span>
}</pre>
        <hr />
        <table width="100%">
            <thead>
                <tr>
                    <th align="center">
                        <small>Generated by</small>
                        <a href="https://github.com/OpenCppCoverage/OpenCppCoverage/releases">
                            <strong>OpenCppCoverage (Version: 0.9.9.0)</strong>
                        </a>
                    </th>
                </tr>
            </thead>
        </table>
    </body>
</html>